---
name: Build disk images

on:
  workflow_dispatch:
    inputs:
      upload-to-s3:
        description: "Upload to S3"
        required: false
        default: false
        type: boolean
      platform:
        required: true
        type: choice
        options:
          - amd64
          - arm64
  pull_request:
    branches:
      - main
    paths:
      - './disk_config/disk.toml'
      - './disk_config/iso.toml'
      - './.github/workflows/build-disk.yml'

env:
  IMAGE_NAME: ${{ github.event.repository.name }} # output of build.yml, keep in sync
  IMAGE_REGISTRY: "ghcr.io/${{ github.repository_owner }}"  # do not edit
  DEFAULT_TAG: "latest"
  
concurrency:
  group: ${{ github.workflow }}-${{ github.ref || github.run_id }}
  cancel-in-progress: true

jobs:
  build:
    name: Build disk images
    runs-on: ${{ inputs.platform == 'amd64' && 'ubuntu-24.04' || 'ubuntu-24.04-arm' }}
    strategy:
      fail-fast: false
      matrix:
        disk-type: ["qcow2", "anaconda-iso"]
    permissions:
      contents: read
      packages: read
      id-token: write

    steps:
      - name: Prepare environment
        run: |
          USER_UID=$(id -u)
          USER_GID=$(id -g)
          # Concatenate the types with a hyphen
          DISK_TYPE=$(echo "${{ matrix.disk-type }}" | tr ' ' '-')
          # Lowercase the image uri
          echo "IMAGE_REGISTRY=${IMAGE_REGISTRY,,}" >> ${GITHUB_ENV}
          echo "IMAGE_NAME=${IMAGE_NAME,,}" >> ${GITHUB_ENV}
          echo "DISK_TYPE=${DISK_TYPE}" >> ${GITHUB_ENV}
          echo "USER_UID=${USER_UID}" >> ${GITHUB_ENV}
          echo "USER_GID=${USER_GID}" >> ${GITHUB_ENV}

      - name: Install dependencies
        if: inputs.platform == 'arm64'
        run: |
          set -x
          sudo apt update -y
          sudo apt install -y \
            podman

      - name: Maximize build space
        if: inputs.platform != 'arm64'
        uses: easimon/maximize-build-space@v10
        with:
          remove-dotnet: "true"
          remove-android: "true"
          remove-haskell: "true"
          remove-codeql: "true"
          remove-docker-images: "true"
          root-reserve-mb: "16384"
          temp-reserve-mb: "2048"
          swap-size-mb: "1024"

      - name: Checkout
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5

      - name: Build disk images
        id: build
        shell: bash
        run: |
          set -euo pipefail
          sudo rm -rf ./output
          mkdir -p ./output
          osbuild_dir="${GITHUB_WORKSPACE}/.osbuild"
          var_tmp_dir="${GITHUB_WORKSPACE}/.var_tmp"
          graphroot="${GITHUB_WORKSPACE}/.containers/storage"
          containers_conf="${GITHUB_WORKSPACE}/containers.conf"
          run_libpod_dir="${GITHUB_WORKSPACE}/.run/libpod"
          run_containers_storage_dir="${GITHUB_WORKSPACE}/.run/containers/storage"
          run_crun_dir="${GITHUB_WORKSPACE}/.run/crun"
          osbuild_store_dir="${GITHUB_WORKSPACE}/.osbuild-store"
          osbuild_rpmmd_dir="${GITHUB_WORKSPACE}/.osbuild-rpmmd"
          sudo rm -rf "${osbuild_dir}" "${var_tmp_dir}" "${graphroot}" "${run_libpod_dir}" "${run_containers_storage_dir}" "${run_crun_dir}" "${osbuild_store_dir}" "${osbuild_rpmmd_dir}"
          sudo mkdir -p "${osbuild_dir}" "${var_tmp_dir}" "${graphroot}" "${run_libpod_dir}" "${run_containers_storage_dir}" "${run_crun_dir}" "${osbuild_store_dir}" "${osbuild_rpmmd_dir}"
          sudo umount /var/lib/containers/storage || true
          sudo rm -rf /var/lib/containers/storage
          sudo mkdir -p /var/lib/containers/storage
          sudo mount --bind "${graphroot}" /var/lib/containers/storage
          cat > "${containers_conf}" <<EOF
          [engine]
          events_logger = "none"
          EOF

          config_file="./disk_config/disk.toml"
          extra_args="--use-librepo=True --rootfs btrfs"
          if [[ "${{ matrix.disk-type }}" == "anaconda-iso" ]]; then
            config_file="./disk_config/iso.toml"
          fi

          sudo CONTAINERS_CONF="${containers_conf}" \
            podman pull "${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.DEFAULT_TAG }}"

          sudo podman run --rm --privileged \
            --security-opt label=type:unconfined_t \
            --volume "${graphroot}:/var/lib/containers/storage" \
            --volume "${osbuild_dir}:/run/osbuild" \
            --volume "${var_tmp_dir}:/var/tmp" \
            --volume "${run_libpod_dir}:/run/libpod" \
            --volume "${run_containers_storage_dir}:/run/containers/storage" \
            --volume "${run_crun_dir}:/run/crun" \
            --volume "${osbuild_store_dir}:/store" \
            --volume "${osbuild_rpmmd_dir}:/rpmmd" \
            --volume ./output:/output \
            --volume "${config_file}:/config.toml:ro" \
            --volume "${containers_conf}:/etc/containers/containers.conf:ro" \
            quay.io/centos-bootc/bootc-image-builder:latest build \
            --output /output \
            --chown "${{ env.USER_UID }}:${{ env.USER_GID }}" \
            ${extra_args} \
            --type "${{ matrix.disk-type }}" \
            "${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.DEFAULT_TAG }}"

          echo "output-directory=$(pwd)/output" >> "$GITHUB_OUTPUT"

          
      - name: Upload disk images and Checksum to Job Artifacts
        if: inputs.upload-to-s3 != true && github.event_name != 'pull_request'
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          path: ${{ steps.build.outputs.output-directory }}
          if-no-files-found: error
          retention-days: 0
          compression-level: 0
          overwrite: true
      
      - name: Upload to S3
        if: inputs.upload-to-s3 == true && github.event_name != 'pull_request'
        shell: bash
        env:
          RCLONE_CONFIG_S3_TYPE: s3
          RCLONE_CONFIG_S3_PROVIDER: ${{ secrets.S3_PROVIDER }}
          RCLONE_CONFIG_S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          RCLONE_CONFIG_S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          RCLONE_CONFIG_S3_REGION: ${{ secrets.S3_REGION }}
          RCLONE_CONFIG_S3_ENDPOINT: ${{ secrets.S3_ENDPOINT }}
          SOURCE_DIR: ${{ steps.build.outputs.output-directory }}
        run: |
          sudo apt-get update
          sudo apt-get install -y rclone
          rclone copy $SOURCE_DIR S3:${{ secrets.S3_BUCKET_NAME }}
